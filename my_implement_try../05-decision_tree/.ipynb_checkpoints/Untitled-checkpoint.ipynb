{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15 entries, 0 to 14\n",
      "Data columns (total 5 columns):\n",
      "age       15 non-null object\n",
      "work      15 non-null object\n",
      "hourse    15 non-null object\n",
      "loan      15 non-null object\n",
      "class     15 non-null object\n",
      "dtypes: object(5)\n",
      "memory usage: 680.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "dataset = pd.read_csv('data.csv')\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_data :  15\n",
      "cols:  ['age', 'work', 'hourse', 'loan', 'class']\n"
     ]
    }
   ],
   "source": [
    "#获取数据集的形状\n",
    "n_data = dataset.shape[0]\n",
    "print(\"n_data : \", n_data)\n",
    "# 得到变量列表，得到格式为list\n",
    "cols = dataset.columns.tolist()\n",
    "print(\"cols: \", cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "object\n",
      "object\n",
      "object\n",
      "object\n",
      "['age', 'work', 'hourse', 'loan', 'class']\n"
     ]
    }
   ],
   "source": [
    "#创建obj_vals列表，并将描述型变量存入\n",
    "obj_vars = []\n",
    "for col in cols:\n",
    "    #print(dataset[col].dtype)\n",
    "    if dataset[col].dtype == \"object\":\n",
    "        obj_vars.append(col)\n",
    "print(obj_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将描述变量转化为数值型变量\n",
    "# 并将转化为的数据附加到原始数据上\n",
    "le = preprocessing.LabelEncoder()\n",
    "for col in obj_vars:\n",
    "    tran = le.fit_transform(dataset[col].tolist())\n",
    "    tran_dataset = pd.DataFrame(tran, columns=['num_'+col])\n",
    "    dataset = pd.concat([dataset, tran_dataset], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding:utf-8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import log\n",
    "\n",
    "def calcEmpiricalEntropy(dataset):\n",
    "    '''\n",
    "    @parameter\n",
    "    dataset： 数据集\n",
    "    output： Empirical Entropy 计算给定数据集的经验熵(H(D))\n",
    "    式子(5-7)\n",
    "    '''\n",
    "    numEntries = dataset.shape[0]  \n",
    "    labelCounts = {} \n",
    "    cols = dataset.columns.tolist() \n",
    "    classlabel = dataset[cols[-1]].tolist() # 将数组或者矩阵转换成列表 \n",
    "    #print(\"classlabel: \", classlabel)\n",
    "    for label in classlabel:\n",
    "        if label not in labelCounts.keys():\n",
    "            labelCounts[label] = 1\n",
    "        else:\n",
    "            labelCounts[label] += 1\n",
    "\n",
    "    EmpiricalEntropy = 0.0\n",
    "\n",
    "    for _, value in labelCounts.items():\n",
    "        prob = value/numEntries\n",
    "        EmpiricalEntropy -= prob*log(prob, 2)\n",
    "\n",
    "    return EmpiricalEntropy\n",
    "\n",
    "def splitDataSet(dataset, axis, value):\n",
    "    '''\n",
    "    input：数据集 所占列 选择值\n",
    "    output：按照给定维度上(axis)的特征的具体取值(value)划分好的子集\n",
    "    描述：按照给定特征划分数据集；选择所占列中等于选择值的项\n",
    "    '''\n",
    "    \n",
    "    cols = dataset.columns.tolist()\n",
    "    axisFeat = dataset[axis].tolist()\n",
    "    #print(\"axisFeat: \", axisFeat)\n",
    "    # 更新数据集\n",
    "    # 去除当前特征值所在的列\n",
    "    retDataSet = pd.concat( [dataset[featVec] for featVec in cols if featVec != axis] , axis=1)\n",
    "    \n",
    "    # 删除与当前特征值不等的行\n",
    "    i = 0\n",
    "    dropIndex = [] #删除项的索引集\n",
    "    for featVec in axisFeat:\n",
    "        if featVec != value:\n",
    "            dropIndex.append(i)\n",
    "        i += 1\n",
    "        \n",
    "    newDataSet = retDataSet.drop(dropIndex)\n",
    "    \n",
    "    return newDataSet.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def chooseMaxInfoGainFeature(dataset):\n",
    "    '''\n",
    "    输入：数据集\n",
    "    输出：最好的划分特征\n",
    "    描述：选择最好的数据集划分维度\n",
    "    式子(5-7),(5-8)\n",
    "    '''\n",
    "    numFeatures = dataset.shape[1] - 1 # 最后一列是结果\n",
    "    HD = calcEmpiricalEntropy(dataset)\n",
    "    #print(\"HD: \", HD)\n",
    "    bestInfoGain = 0.0\n",
    "    bestFeature = -1\n",
    "    cols = dataset.columns.tolist()\n",
    "    \n",
    "    for i in range(numFeatures): #  \n",
    "        equalVals = set(dataset[cols[i]].tolist()) # 这些特征的具体取值范围\n",
    "        empirCondEntropy = 0.0\n",
    "        for value in equalVals: # i--> n 对特征的取值进行求经验熵的和 第一个求和号\n",
    "            # 函数 splitDataSet() 获取由特征不同取值划分的数据集\n",
    "            subDataSet = splitDataSet(dataset, cols[i], value)\n",
    "            # print(\"subDataSet: \", subDataSet)\n",
    "            # |Di| : subDataSet.shape[0] \n",
    "            # |D| : dataset.shape[0]\n",
    "            prob = subDataSet.shape[0] / dataset.shape[0]\n",
    "            empirCondEntropy += prob * calcEmpiricalEntropy(subDataSet)\n",
    "        infoGain = HD - empirCondEntropy\n",
    "        #print(cols[i],infoGain)\n",
    "        if infoGain > bestInfoGain:\n",
    "            bestInfoGain = infoGain\n",
    "            bestFeature = cols[i]\n",
    "    return bestFeature, bestInfoGain\n",
    "\n",
    "def majorityVote(classList):\n",
    "    '''\n",
    "    输入：分类类别列表\n",
    "    输出：子节点的分类\n",
    "    描述：数据集已经处理了所有属性，但是类标签依然不是唯一的，\n",
    "          采用多数判决的方法决定该子节点的分类\n",
    "    '''\n",
    "    classCount = {}\n",
    "    for vote in classList:\n",
    "        if vote not in classCount.keys():\n",
    "            classCount[vote] = 0\n",
    "        classCount[vote] += 1\n",
    "    sortedValue = sorted(classCount.items(), key=lambda item:item[1], reversed=True)\n",
    "    return sortedValue[0][0]\n",
    "\n",
    "def createTree(dataset):\n",
    "    '''\n",
    "    输入：数据集，删除特征\n",
    "    输出：决策树\n",
    "    描述：递归构建决策树，利用上述的函数\n",
    "    '''\n",
    "    cols = dataset.columns.tolist()[:-1]\n",
    "    classList = dataset[dataset.columns.tolist()[-1]].tolist()\n",
    "\n",
    "    \n",
    "    \n",
    "    # 终止条件\n",
    "    # 若数据集中所有实例属于同一类Ck，则为单节点树，并将Ck作为该节点的类标记\n",
    "    if classList.count(classList[0]) == len(classList):\n",
    "        return classList[0]\n",
    "\n",
    "    # 若特征集为空集，则为单节点树，并将数据集中实例数最大的类Ck作为该节点的类标记\n",
    "    if len(cols) == 0:\n",
    "        return majorityVote(classList)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('特征集和类别:',dataset.columns.tolist())\n",
    "    bestFeature, bestInfoGain = chooseMaxInfoGainFeature(dataset)\n",
    "    print('bestFeture:',bestFeature)\n",
    "\n",
    "    decisionTree = {bestFeature:{}}\n",
    "\n",
    "    # 得到列表包括节点所有的属性值\n",
    "    featValues = set(dataset[bestFeature])\n",
    "    for value in featValues:\n",
    "        decisionTree[bestFeature][value] = createTree( splitDataSet(dataset, bestFeature, value) )\n",
    "    return decisionTree\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征集和类别: ['age', 'work', 'house', 'loan', 'class']\n",
      "bestFeture: house\n",
      "特征集和类别: ['age', 'work', 'loan', 'class']\n",
      "bestFeture: work\n",
      "{'house': {'是': '是', '否': {'work': {'是': '是', '否': '否'}}}}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dtModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-550b22be9ee5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     export_graphviz(\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mdtModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mout_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mclass_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'同意贷款'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'不同意贷款'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dtModel' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    dataset = pd.read_csv(\"data.csv\")\n",
    "    DeciTree = createTree(dataset)\n",
    "    print(DeciTree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "特征集和类别: ['age', 'work', 'hourse', 'loan', 'class']\n",
    "bestFeture: hourse\n",
    "hourse\n",
    "特征集和类别: ['age', 'work', 'loan', 'class']\n",
    "bestFeture: work\n",
    "work\n",
    "{'hourse': {'是': '是', '否': {'work': {'是': '是', '否': '否'}}}}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
